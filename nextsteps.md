# Ideas for next steps based on X feedback

## Karpathy idea: use one LLM but vary the prompt
--give different instances of the same model different prompts, and then carry out the different procedures

## Tabarrok idea: weight the votes by rates of correctness
--Do a pre-study where you compute rates of accurateness for different models, then weight their votes by these accuracy rates

--alternatively, weight by size of model or other quant indicator of quality

## Ittai idea: malicious voter

--give one model a prompt to try to mess with the votes of the others

## MetaMood_ idea from X: evaluate quality across number of models participating

--should be like an upside down U curve

## Ethan/Pablo: the PE angle

--link to juries/committees

## Think about additional procedures, different prompts, different models
